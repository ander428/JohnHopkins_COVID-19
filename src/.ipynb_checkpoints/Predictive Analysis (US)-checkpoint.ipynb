{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from IPython.display import display_html\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn import datasets\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 8)\n",
    "pd.set_option(\"display.max_columns\", 20)\n",
    "\n",
    "def frange(start, stop, step):\n",
    "    i = start\n",
    "    while i < stop:\n",
    "        yield round(i, ndigits=2)\n",
    "        i += step\n",
    "        \n",
    "def save_model(model, filepath):\n",
    "    with open(filepath, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "        \n",
    "def load_model(filepath):\n",
    "    with open(filepath, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***I remove excess columns that ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_US = pd.read_csv(\"../data/US_all_vars.csv\").iloc[:,1:]\n",
    "cases_US['Date'] = pd.to_datetime(cases_US['Date'], cache=True)\n",
    "cases_US['Date'] = cases_US['Date'].apply(lambda x:x.toordinal())\n",
    "cases_US = cases_US.drop(['FIPS', 'Country_Region', 'Total_Cases', 'County', 'State', 'County_FIPS',\n",
    "                          'Phase.0', 'Phase.1', 'Phase.2', 'Phase.3', 'Abbreviation', 'Month',\n",
    "                          'Lat', 'Long'],axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "def calc_vif(X, thresh=5.0):\n",
    "    # Calculating VIF\n",
    "    X_numeric = X.select_dtypes(['float64', 'int64'])\n",
    "    vif = pd.DataFrame()\n",
    "    variables = list(range(X_numeric.shape[1]))\n",
    "    dropped = pd.DataFrame(columns=['variable','VIF'])\n",
    "    \n",
    "    while True:\n",
    "        vif = pd.DataFrame()\n",
    "        vif[\"variable\"] = X_numeric.iloc[:, variables].columns\n",
    "        vif[\"VIF\"] = [variance_inflation_factor(X_numeric.iloc[:, variables].values, i) \n",
    "                  for i in range(X_numeric.iloc[:, variables].shape[1])]\n",
    "        max_i = vif['VIF'].idxmax()\n",
    "        if(vif['VIF'].max() > thresh):\n",
    "            dropped = dropped.append({\n",
    "                'variable': X_numeric.iloc[:, variables].columns[max_i],\n",
    "                'VIF': vif.loc[max_i, \"VIF\"]\n",
    "            }, ignore_index=True)\n",
    "            variables.pop(max_i)\n",
    "            continue\n",
    "        break\n",
    "\n",
    "    return vif, dropped\n",
    "\n",
    "vif, dropped = calc_vif(cases_US)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113\" style='display:inline'><caption>US VIF Values</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >variable</th>        <th class=\"col_heading level0 col1\" >VIF</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row0_col0\" class=\"data row0 col0\" >Current_Phase</td>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row0_col1\" class=\"data row0 col1\" >1.079262</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row1_col0\" class=\"data row1 col0\" >Cases_2W</td>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row1_col1\" class=\"data row1 col1\" >2.592251</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row2_col0\" class=\"data row2 col0\" >Cases_Delta</td>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row2_col1\" class=\"data row2 col1\" >2.342335</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row3_col0\" class=\"data row3 col0\" >Protest_Count</td>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row3_col1\" class=\"data row3 col1\" >3.355170</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row4_col0\" class=\"data row4 col0\" >Perc.Over.65</td>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row4_col1\" class=\"data row4 col1\" >3.693477</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row5_col0\" class=\"data row5 col0\" >Perc.Black</td>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row5_col1\" class=\"data row5 col1\" >1.337205</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row6_col0\" class=\"data row6 col0\" >Perc.Native</td>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row6_col1\" class=\"data row6 col1\" >1.439563</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row7_col0\" class=\"data row7 col0\" >Perc.Asian</td>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row7_col1\" class=\"data row7 col1\" >2.611873</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row8_col0\" class=\"data row8 col0\" >Perc.Pac.Island</td>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row8_col1\" class=\"data row8 col1\" >1.729726</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row9_col0\" class=\"data row9 col0\" >Perc.Mixed</td>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row9_col1\" class=\"data row9 col1\" >4.953321</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row10_col0\" class=\"data row10 col0\" >Perc.His.Lat</td>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row10_col1\" class=\"data row10 col1\" >1.606880</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row11_col0\" class=\"data row11 col0\" >POP.2019</td>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row11_col1\" class=\"data row11 col1\" >3.249685</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row12_col0\" class=\"data row12 col0\" >Area.sq.km</td>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row12_col1\" class=\"data row12 col1\" >1.869055</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row13_col0\" class=\"data row13 col0\" >PopDensity</td>\n",
       "                        <td id=\"T_64ef69b4_d160_11ea_8cf9_001a7dda7113row13_col1\" class=\"data row13 col1\" >1.431094</td>\n",
       "            </tr>\n",
       "    </tbody></table><style  type=\"text/css\" >\n",
       "</style><table id=\"T_64ef90a4_d160_11ea_9dfa_001a7dda7113\" style='display:inline'><caption>Variables removed for high multicolinearity</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >variable</th>        <th class=\"col_heading level0 col1\" >VIF</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_64ef90a4_d160_11ea_9dfa_001a7dda7113level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_64ef90a4_d160_11ea_9dfa_001a7dda7113row0_col0\" class=\"data row0 col0\" >Date</td>\n",
       "                        <td id=\"T_64ef90a4_d160_11ea_9dfa_001a7dda7113row0_col1\" class=\"data row0 col1\" >2068758.493965</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ef90a4_d160_11ea_9dfa_001a7dda7113level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_64ef90a4_d160_11ea_9dfa_001a7dda7113row1_col0\" class=\"data row1 col0\" >Perc.White</td>\n",
       "                        <td id=\"T_64ef90a4_d160_11ea_9dfa_001a7dda7113row1_col1\" class=\"data row1 col1\" >656.103652</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ef90a4_d160_11ea_9dfa_001a7dda7113level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_64ef90a4_d160_11ea_9dfa_001a7dda7113row2_col0\" class=\"data row2 col0\" >Perc.Female</td>\n",
       "                        <td id=\"T_64ef90a4_d160_11ea_9dfa_001a7dda7113row2_col1\" class=\"data row2 col1\" >263.354220</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ef90a4_d160_11ea_9dfa_001a7dda7113level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_64ef90a4_d160_11ea_9dfa_001a7dda7113row3_col0\" class=\"data row3 col0\" >Avg.Person.Per.Household</td>\n",
       "                        <td id=\"T_64ef90a4_d160_11ea_9dfa_001a7dda7113row3_col1\" class=\"data row3 col1\" >36.226167</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ef90a4_d160_11ea_9dfa_001a7dda7113level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_64ef90a4_d160_11ea_9dfa_001a7dda7113row4_col0\" class=\"data row4 col0\" >Avg_Temp</td>\n",
       "                        <td id=\"T_64ef90a4_d160_11ea_9dfa_001a7dda7113row4_col1\" class=\"data row4 col1\" >20.635085</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_64ef90a4_d160_11ea_9dfa_001a7dda7113level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_64ef90a4_d160_11ea_9dfa_001a7dda7113row5_col0\" class=\"data row5 col0\" >Perc.Foreign.Born</td>\n",
       "                        <td id=\"T_64ef90a4_d160_11ea_9dfa_001a7dda7113row5_col1\" class=\"data row5 col1\" >7.358210</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1_styler = (vif.style\n",
    "                  .set_table_attributes(\"style='display:inline'\")\n",
    "                  .set_caption('US VIF Values'))\n",
    "df2_styler = (dropped.style\n",
    "                  .set_table_attributes(\"style='display:inline'\")\n",
    "                  .set_caption('Variables removed for high multicolinearity'))\n",
    "\n",
    "display_html(df1_styler._repr_html_()+df2_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = list(dropped['variable'])\n",
    "drop.append('Cases_2W')\n",
    "x, y = cases_US.drop(drop,axis=1).select_dtypes(['float64', 'int64']), cases_US['Cases_2W']\n",
    "\n",
    "# 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3,random_state=109) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 52.3min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 191.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators='warn',\n",
       "                                                   n_jobs=None, oob_score=False,\n",
       "                                                   random_state=None, verbose=0,\n",
       "                                                   warm_start=False),\n",
       "                   iid='warn', n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800,\n",
       "                                                         900, 1000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100,\n",
    "                               cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'rf_random' (RandomizedSearchCV)\n"
     ]
    }
   ],
   "source": [
    "%store rf_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r rf_random\n",
    "model = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average RMSE: 357.8441 cases.\n",
      "Average MAE: 41.0963 cases.\n",
      "R2 = 0.96%.\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    print('Model Performance')\n",
    "    print('Average RMSE: {:0.4f} cases.'.format(sqrt(mean_squared_error(predictions, test_labels))))\n",
    "    print('Average MAE: {:0.4f} cases.'.format(mean_absolute_error(predictions, test_labels)))\n",
    "    print('R2 = {:0.2f}%.'.format(r2_score(predictions, test_labels)))\n",
    "\n",
    "evaluate(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'split0_test_precision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-244c5f7d54f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# save_model(rf_random, \"../models/random_forest_cv.sav\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# temp = load_model(\"../models/random_forest_cv.sav\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"split0_test_precision\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'split0_test_precision'"
     ]
    }
   ],
   "source": [
    "# save_model(rf_random, \"../models/random_forest_cv.sav\")\n",
    "# temp = load_model(\"../models/random_forest_cv.sav\")\n",
    "temp.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: Restriction Rating   Importance: 0.32\n",
      "Variable: Date                 Importance: 0.18\n",
      "Variable: Governer.Party       Importance: 0.16\n",
      "Variable: Perc.Female          Importance: 0.11\n",
      "Variable: Perc.Native          Importance: 0.08\n",
      "Variable: Avg_Temp             Importance: 0.03\n",
      "Variable: Perc.Black           Importance: 0.03\n",
      "Variable: Current_Phase        Importance: 0.02\n",
      "Variable: Cases_2W             Importance: 0.02\n",
      "Variable: Perc.Over.65         Importance: 0.02\n",
      "Variable: Perc.White           Importance: 0.02\n",
      "Variable: Cases_Delta          Importance: 0.01\n",
      "Variable: Protest_Count        Importance: 0.01\n"
     ]
    }
   ],
   "source": [
    "importances = list(model.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(list(cases_US.columns), importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "cudagpu",
   "language": "python",
   "name": "cudagpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
