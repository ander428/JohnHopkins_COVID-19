{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import random\n",
    "from collections import deque\n",
    "import itertools\n",
    "from IPython.display import display_html, Image\n",
    "\n",
    "import pickle\n",
    "import pydotplus\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.externals.six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import ColumnDataSource, HoverTool, Span, Label\n",
    "from bokeh.palettes import Category10\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 8)\n",
    "pd.set_option(\"display.max_columns\", 20)\n",
    "\n",
    "def frange(start, stop, step):\n",
    "    i = start\n",
    "    while i < stop:\n",
    "        yield round(i, ndigits=2)\n",
    "        i += step\n",
    "        \n",
    "def save_model(model, filepath):\n",
    "    with open(filepath, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "        \n",
    "def load_model(filepath):\n",
    "    with open(filepath, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_US = pd.read_csv(\"../data/US_all_vars.csv\").iloc[:,1:]\n",
    "cases_US['Date'] = pd.to_datetime(cases_US['Date'], cache=True)\n",
    "# cases_US['Date'] = cases_US['Date'].apply(lambda x:x.toordinal())\n",
    "cases_US = cases_US.drop(['FIPS', 'Country_Region', 'Total_Cases', 'State', 'County_FIPS',\n",
    "                          'Phase.0', 'Phase.1', 'Phase.2', 'Phase.3', 'Abbreviation', 'Month',\n",
    "                          'Lat', 'Long'],axis=1)\n",
    "\n",
    "# cases_US = cases_US.groupby(['County', 'Date']).agg({\n",
    "#     'Restriction Rating': pd.Series.mode,\n",
    "#     'Governer.Party': pd.Series.mode,\n",
    "#     'Current_Phase': pd.Series.mode,\n",
    "#     'Cases_Delta': np.sum,\n",
    "#     'Avg_Temp': np.mean,\n",
    "#     'Protest_Count': np.sum,\n",
    "#     'Perc.Over.65': np.mean,\n",
    "#     'Perc.White': np.mean,\n",
    "#     'Perc.Female': np.mean,\n",
    "#     'Perc.Black': np.mean,\n",
    "#     'Perc.Native': np.mean,\n",
    "#     'Perc.Asian': np.mean,\n",
    "#     'Perc.Pac.Island': np.mean,\n",
    "#     'Perc.Mixed': np.mean,\n",
    "#     'Perc.His.Lat': np.mean,\n",
    "#     'Perc.Foreign.Born': np.mean,\n",
    "#     'Avg.Person.Per.Household': np.mean,\n",
    "#     'POP.2019': np.sum,\n",
    "#     'Area.sq.km': np.sum,\n",
    "#     'PopDensity': np.mean,\n",
    "#     'Cases_2W': np.sum\n",
    "# }).reset_index().dropna()\n",
    "\n",
    "cases_US = cases_US.drop(['Area.sq.km', 'POP.2019'], axis=1)\n",
    "cases_US_curr = cases_US[cases_US['Date'] == pd.Timestamp('2020-06-16')]\n",
    "\n",
    "cases_US = cases_US.set_index(['County', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_US_curr = (pd.concat([cases_US_curr, pd.get_dummies(cases_US_curr['Restriction Rating']),\n",
    "          pd.get_dummies(cases_US_curr['Governer.Party'])], axis=1)\n",
    " .drop(['Current_Phase', 'Restriction Rating', 'Governer.Party', 'Date'], axis=1)).set_index('County')\n",
    "temp = cases_US_curr['Cases_2W']\n",
    "cases_US_curr = cases_US_curr.drop('Cases_2W', axis=1)\n",
    "cases_US_curr['Cases_2W'] = temp\n",
    "cases_US_curr = cases_US_curr.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vif(X, thresh=10.0):\n",
    "    # Calculating VIF\n",
    "    X_numeric = X.select_dtypes(['float64', 'int64'])\n",
    "    vif = pd.DataFrame()\n",
    "    variables = list(range(X_numeric.shape[1]))\n",
    "    dropped = pd.DataFrame(columns=['variable','VIF'])\n",
    "    \n",
    "    while True:\n",
    "        vif = pd.DataFrame()\n",
    "        vif[\"variable\"] = X_numeric.iloc[:, variables].columns\n",
    "        vif[\"VIF\"] = [variance_inflation_factor(X_numeric.iloc[:, variables].values, i) \n",
    "                  for i in range(X_numeric.iloc[:, variables].shape[1])]\n",
    "        max_i = vif['VIF'].idxmax()\n",
    "        if(vif['VIF'].max() > thresh):\n",
    "            # Keep avg temp as a variable and remove 2nd largest vif value\n",
    "            if X_numeric.iloc[:, variables].columns[max_i] == 'Avg_Temp':\n",
    "                max_2nd = vif['VIF'].nlargest(2).iloc[1:].values[0]\n",
    "                if max_2nd <= thresh:\n",
    "                    continue\n",
    "                else:\n",
    "                    max_i = vif['VIF'].nlargest(2).iloc[1:].index[0]\n",
    "            dropped = dropped.append({\n",
    "                'variable': X_numeric.iloc[:, variables].columns[max_i],\n",
    "                'VIF': vif.loc[max_i, \"VIF\"]\n",
    "            }, ignore_index=True)\n",
    "            variables.pop(max_i)\n",
    "            continue\n",
    "        break\n",
    "\n",
    "    return vif, dropped\n",
    "\n",
    "vif, dropped = calc_vif(cases_US_curr.iloc[:,:-9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cases_Delta</th>\n",
       "      <th>Avg_Temp</th>\n",
       "      <th>Protest_Count</th>\n",
       "      <th>Perc.Over.65</th>\n",
       "      <th>Perc.White</th>\n",
       "      <th>Perc.Female</th>\n",
       "      <th>Perc.Black</th>\n",
       "      <th>Perc.Native</th>\n",
       "      <th>Perc.Asian</th>\n",
       "      <th>Perc.Pac.Island</th>\n",
       "      <th>Perc.Mixed</th>\n",
       "      <th>Perc.His.Lat</th>\n",
       "      <th>Perc.Foreign.Born</th>\n",
       "      <th>Avg.Person.Per.Household</th>\n",
       "      <th>PopDensity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>County</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abbeville</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>76.10000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>18.70000</td>\n",
       "      <td>69.90000</td>\n",
       "      <td>51.40000</td>\n",
       "      <td>28.20000</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.30000</td>\n",
       "      <td>1.20000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.49000</td>\n",
       "      <td>19.30746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acadia</th>\n",
       "      <td>21.00000</td>\n",
       "      <td>80.20000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accomack</th>\n",
       "      <td>11.00000</td>\n",
       "      <td>74.20000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>20.80000</td>\n",
       "      <td>69.00000</td>\n",
       "      <td>51.50000</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>0.60000</td>\n",
       "      <td>0.60000</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>2.25000</td>\n",
       "      <td>27.75811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ada</th>\n",
       "      <td>71.00000</td>\n",
       "      <td>64.20000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>12.10000</td>\n",
       "      <td>92.50000</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>1.30000</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>2.60000</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>2.60000</td>\n",
       "      <td>7.50000</td>\n",
       "      <td>5.90000</td>\n",
       "      <td>2.60000</td>\n",
       "      <td>176.65322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yuma</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>74.40000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>17.20000</td>\n",
       "      <td>97.30000</td>\n",
       "      <td>49.90000</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>21.60000</td>\n",
       "      <td>10.90000</td>\n",
       "      <td>2.61000</td>\n",
       "      <td>1.63608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zapata</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>84.40000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11.20000</td>\n",
       "      <td>98.60000</td>\n",
       "      <td>49.60000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>93.50000</td>\n",
       "      <td>24.50000</td>\n",
       "      <td>3.17000</td>\n",
       "      <td>5.48326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zavala</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>83.20000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>12.50000</td>\n",
       "      <td>96.90000</td>\n",
       "      <td>50.20000</td>\n",
       "      <td>1.20000</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.70000</td>\n",
       "      <td>92.90000</td>\n",
       "      <td>11.20000</td>\n",
       "      <td>3.15000</td>\n",
       "      <td>3.52352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ziebach</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>69.30000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>24.30000</td>\n",
       "      <td>50.40000</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>71.60000</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.40000</td>\n",
       "      <td>3.70000</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>3.51000</td>\n",
       "      <td>0.54255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3240 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Cases_Delta  Avg_Temp  Protest_Count  Perc.Over.65  Perc.White  \\\n",
       "County                                                                      \n",
       "Abbeville      0.00000  76.10000        0.00000      18.70000    69.90000   \n",
       "Acadia        21.00000  80.20000        1.00000           nan         nan   \n",
       "Accomack      11.00000  74.20000        2.00000      20.80000    69.00000   \n",
       "Ada           71.00000  64.20000        1.00000      12.10000    92.50000   \n",
       "...                ...       ...            ...           ...         ...   \n",
       "Yuma           0.00000  74.40000        0.00000      17.20000    97.30000   \n",
       "Zapata         1.00000  84.40000        0.00000      11.20000    98.60000   \n",
       "Zavala         0.00000  83.20000        0.00000      12.50000    96.90000   \n",
       "Ziebach        0.00000  69.30000        0.00000       7.00000    24.30000   \n",
       "\n",
       "           Perc.Female  Perc.Black  Perc.Native  Perc.Asian  Perc.Pac.Island  \\\n",
       "County                                                                         \n",
       "Abbeville     51.40000    28.20000      0.30000     0.40000          0.00000   \n",
       "Acadia             nan         nan          nan         nan              nan   \n",
       "Accomack      51.50000    28.00000      0.60000     0.60000          0.20000   \n",
       "Ada           50.00000     1.30000      0.80000     2.60000          0.20000   \n",
       "...                ...         ...          ...         ...              ...   \n",
       "Yuma          49.90000     0.30000      0.90000     0.40000          0.20000   \n",
       "Zapata        49.60000     0.50000      0.40000     0.20000          0.00000   \n",
       "Zavala        50.20000     1.20000      0.90000     0.10000          0.10000   \n",
       "Ziebach       50.40000     0.40000     71.60000     0.30000          0.00000   \n",
       "\n",
       "           Perc.Mixed  Perc.His.Lat  Perc.Foreign.Born  \\\n",
       "County                                                   \n",
       "Abbeville     1.30000       1.20000            1.00000   \n",
       "Acadia            nan           nan                nan   \n",
       "Accomack      1.50000       9.00000            7.00000   \n",
       "Ada           2.60000       7.50000            5.90000   \n",
       "...               ...           ...                ...   \n",
       "Yuma          0.80000      21.60000           10.90000   \n",
       "Zapata        0.20000      93.50000           24.50000   \n",
       "Zavala        0.70000      92.90000           11.20000   \n",
       "Ziebach       3.40000       3.70000            0.90000   \n",
       "\n",
       "           Avg.Person.Per.Household  PopDensity  \n",
       "County                                           \n",
       "Abbeville                   2.49000    19.30746  \n",
       "Acadia                          nan         nan  \n",
       "Accomack                    2.25000    27.75811  \n",
       "Ada                         2.60000   176.65322  \n",
       "...                             ...         ...  \n",
       "Yuma                        2.61000     1.63608  \n",
       "Zapata                      3.17000     5.48326  \n",
       "Zavala                      3.15000     3.52352  \n",
       "Ziebach                     3.51000     0.54255  \n",
       "\n",
       "[3240 rows x 15 columns]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_US_curr.iloc[:,:-9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_94695db0_d22c_11ea_931f_001a7dda7113\" style='display:inline'><caption>US VIF Values</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >variable</th>        <th class=\"col_heading level0 col1\" >VIF</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_94695db0_d22c_11ea_931f_001a7dda7113level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row0_col0\" class=\"data row0 col0\" >Cases_Delta</td>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row0_col1\" class=\"data row0 col1\" >1.356432</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_94695db0_d22c_11ea_931f_001a7dda7113level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row1_col0\" class=\"data row1 col0\" >Avg_Temp</td>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row1_col1\" class=\"data row1 col1\" >5.076446</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_94695db0_d22c_11ea_931f_001a7dda7113level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row2_col0\" class=\"data row2 col0\" >Protest_Count</td>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row2_col1\" class=\"data row2 col1\" >2.103504</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_94695db0_d22c_11ea_931f_001a7dda7113level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row3_col0\" class=\"data row3 col0\" >Perc.Black</td>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row3_col1\" class=\"data row3 col1\" >1.519322</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_94695db0_d22c_11ea_931f_001a7dda7113level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row4_col0\" class=\"data row4 col0\" >Perc.Native</td>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row4_col1\" class=\"data row4 col1\" >1.359629</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_94695db0_d22c_11ea_931f_001a7dda7113level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row5_col0\" class=\"data row5 col0\" >Perc.Asian</td>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row5_col1\" class=\"data row5 col1\" >3.389680</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_94695db0_d22c_11ea_931f_001a7dda7113level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row6_col0\" class=\"data row6 col0\" >Perc.Pac.Island</td>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row6_col1\" class=\"data row6 col1\" >1.723153</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_94695db0_d22c_11ea_931f_001a7dda7113level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row7_col0\" class=\"data row7 col0\" >Perc.Mixed</td>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row7_col1\" class=\"data row7 col1\" >5.349729</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_94695db0_d22c_11ea_931f_001a7dda7113level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row8_col0\" class=\"data row8 col0\" >Perc.His.Lat</td>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row8_col1\" class=\"data row8 col1\" >3.759431</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_94695db0_d22c_11ea_931f_001a7dda7113level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row9_col0\" class=\"data row9 col0\" >Perc.Foreign.Born</td>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row9_col1\" class=\"data row9 col1\" >7.367302</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_94695db0_d22c_11ea_931f_001a7dda7113level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row10_col0\" class=\"data row10 col0\" >PopDensity</td>\n",
       "                        <td id=\"T_94695db0_d22c_11ea_931f_001a7dda7113row10_col1\" class=\"data row10 col1\" >1.397636</td>\n",
       "            </tr>\n",
       "    </tbody></table><style  type=\"text/css\" >\n",
       "</style><table id=\"T_946984a8_d22c_11ea_86fc_001a7dda7113\" style='display:inline'><caption>Variables removed for high multicolinearity</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >variable</th>        <th class=\"col_heading level0 col1\" >VIF</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_946984a8_d22c_11ea_86fc_001a7dda7113level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_946984a8_d22c_11ea_86fc_001a7dda7113row0_col0\" class=\"data row0 col0\" >Perc.White</td>\n",
       "                        <td id=\"T_946984a8_d22c_11ea_86fc_001a7dda7113row0_col1\" class=\"data row0 col1\" >696.964249</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_946984a8_d22c_11ea_86fc_001a7dda7113level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_946984a8_d22c_11ea_86fc_001a7dda7113row1_col0\" class=\"data row1 col0\" >Perc.Female</td>\n",
       "                        <td id=\"T_946984a8_d22c_11ea_86fc_001a7dda7113row1_col1\" class=\"data row1 col1\" >316.947887</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_946984a8_d22c_11ea_86fc_001a7dda7113level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_946984a8_d22c_11ea_86fc_001a7dda7113row2_col0\" class=\"data row2 col0\" >Avg.Person.Per.Household</td>\n",
       "                        <td id=\"T_946984a8_d22c_11ea_86fc_001a7dda7113row2_col1\" class=\"data row2 col1\" >103.292748</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_946984a8_d22c_11ea_86fc_001a7dda7113level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_946984a8_d22c_11ea_86fc_001a7dda7113row3_col0\" class=\"data row3 col0\" >Perc.Over.65</td>\n",
       "                        <td id=\"T_946984a8_d22c_11ea_86fc_001a7dda7113row3_col1\" class=\"data row3 col1\" >18.447256</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drop = list(dropped['variable'])\n",
    "cases_US_curr = cases_US_curr.drop(drop,axis=1)\n",
    "\n",
    "df1_styler = (vif.style\n",
    "                  .set_table_attributes(\"style='display:inline'\")\n",
    "                  .set_caption('US VIF Values'))\n",
    "df2_styler = (dropped.style\n",
    "                  .set_table_attributes(\"style='display:inline'\")\n",
    "                  .set_caption('Variables removed for high multicolinearity'))\n",
    "\n",
    "display_html(df1_styler._repr_html_()+df2_styler._repr_html_(), raw=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x, y = cases_US_curr.iloc[:,:-1], cases_US_curr['Cases_2W']\n",
    "\n",
    "# 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25,random_state=110) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  3.0min finished\n"
     ]
    }
   ],
   "source": [
    "# # Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['auto', 'sqrt']\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [int(x) for x in np.linspace(start = 2, stop = 11, num = 10)]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [int(x) for x in np.linspace(start = 1, stop = 5, num = 5)]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100,\n",
    "                               cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "save_model(rf_random, \"../models/random_forest_cv.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random = load_model(\"../models/random_forest_cv.sav\")\n",
    "rf_model = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(rf_random.cv_results_)\n",
    "results.loc[results['rank_test_score'] > 1, 'color'] = 'blue'\n",
    "results.loc[results['rank_test_score'] == 1, 'color'] = 'red'\n",
    "best_n = results.loc[results['mean_test_score'] == results['mean_test_score'].max(), 'param_n_estimators'].values[0]\n",
    "\n",
    "hover = HoverTool(tooltips=[\n",
    "    ('Estimators', '@n_estimators'),\n",
    "    ('Score', '@score{0.00000}'),\n",
    "    ('Max Features', '@param_max_features'),\n",
    "    ('Bootstrap', '@param_bootstrap')\n",
    "    ])\n",
    "\n",
    "p = figure(title = \"CV of Random Forest Model\", plot_height=500, plot_width=750,\n",
    "           tools=[hover])\n",
    "\n",
    "source = ColumnDataSource(data=dict(\n",
    "    color=results['color'],\n",
    "    n_estimators=results['param_n_estimators'],\n",
    "    score=results['mean_test_score'],\n",
    "    param_max_features=results['param_max_features'],\n",
    "    param_bootstrap=results['param_bootstrap'],\n",
    "\n",
    "))\n",
    "\n",
    "\n",
    "p.circle('n_estimators', 'score',line_width=2, source=source)\n",
    "vline = Span(location=best_n, dimension='height', line_color='red', line_dash='dashed',line_width=2)\n",
    "p.renderers.extend([vline])\n",
    "\n",
    "p.xaxis.axis_label = '# of Trees'\n",
    "p.yaxis.axis_label = 'coefficient of determination (r²)'\n",
    "\n",
    "output_file('../assets/img/Bokeh/rf_cv.html')\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe src=\"assets/img/Bokeh/rf_cv.html\"\n",
    "    sandbox=\"allow-same-origin allow-scripts\"\n",
    "    width=\"100%\"\n",
    "    height=\"550\"\n",
    "    scrolling=\"no\"\n",
    "    seamless=\"seamless\"\n",
    "    frameborder=\"0\">\n",
    "</iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "944"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[results['mean_test_score'] == results['mean_test_score'].max(), 'param_n_estimators'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average RMSE</th>\n",
       "      <th>Average MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1268.54348</td>\n",
       "      <td>325.19321</td>\n",
       "      <td>0.55932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average RMSE  Average MAE      R2\n",
       "0    1268.54348    325.19321 0.55932"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    return pd.DataFrame({\n",
    "        'Average RMSE': [sqrt(mean_squared_error(predictions, test_labels))],\n",
    "        'Average MAE': [mean_absolute_error(predictions, test_labels)],\n",
    "        'R2': [r2_score(predictions, test_labels)]\n",
    "    })\n",
    "evaluate(rf_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = list(rf_model.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(list(cases_US.columns), importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1])\n",
    "feature_importances = dict(feature_importances)\n",
    "\n",
    "\n",
    "hover = HoverTool(tooltips=[\n",
    "    ('Variable', '@Variables'),\n",
    "    ('Importance', '@Importance{0.00}')\n",
    "    ])\n",
    "\n",
    "p = figure(y_range=list(feature_importances.keys()), plot_height=500, width=750, \n",
    "           title=\"Random Forest Variable Importance\", tools=[hover])\n",
    "source=ColumnDataSource(data=dict(\n",
    "    Variables=list(feature_importances.keys()),\n",
    "    Importance=list(feature_importances.values())\n",
    "))\n",
    "\n",
    "p.hbar(y='Variables', right='Importance',left=0, height=0.9, source=source)\n",
    "p.yaxis.major_label_orientation = \"horizontal\"\n",
    "\n",
    "p.xaxis.axis_label = 'Variable Importance'\n",
    "p.yaxis.axis_label = 'Vasriable Name'\n",
    "p.ygrid.grid_line_color = None\n",
    "\n",
    "output_file('../assets/img/Bokeh/rf_imp.html')\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe src=\"assets/img/Bokeh/rf_imp.html\"\n",
    "    sandbox=\"allow-same-origin allow-scripts\"\n",
    "    width=\"100%\"\n",
    "    height=\"550\"\n",
    "    scrolling=\"no\"\n",
    "    seamless=\"seamless\"\n",
    "    frameborder=\"0\">\n",
    "</iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-8a18e43f6862>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                 special_characters=True)\n\u001b[0;32m      5\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, prog)\u001b[0m\n\u001b[0;32m   1795\u001b[0m             self.__setattr__(\n\u001b[0;32m   1796\u001b[0m                 \u001b[1;34m'create_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfrmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1797\u001b[1;33m                 \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1798\u001b[0m             )\n\u001b[0;32m   1799\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'create_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfrmt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1958\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m                 raise InvocationException(\n\u001b[1;32m-> 1960\u001b[1;33m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[0;32m   1961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1962\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprog\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(rf_model.estimators_[0], out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = cases_US.index.get_level_values(1)\n",
    "sequence_length = max(dates)-min(dates)\n",
    "\n",
    "def preprocess_data(data, label_name, process_vals):\n",
    "    for col in process_vals:\n",
    "        if data[col].dtype == 'int64' or data[col].dtype == 'float64':\n",
    "            data[col] = data[col].pct_change() # normalizes variables\n",
    "            data = data.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "            data[col] = preprocessing.scale(data[col].values)\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    seq_data = []\n",
    "    prev_days = deque(maxlen=sequence_length)\n",
    "    for val in data.values:\n",
    "        prev_days.append([n for n in val[:-1]])\n",
    "        if len(prev_days) == sequence_length:\n",
    "            seq_data.append([np.array(prev_days), val[-1]])\n",
    "    \n",
    "    random.shuffle(seq_data)\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for x_i, y_i in seq_data:\n",
    "        X.append(x_i)\n",
    "        y.append(y_i)\n",
    "    \n",
    "    return np.array(X), y\n",
    "\n",
    "times = cases_US.index.get_level_values(1).values\n",
    "\n",
    "last_5perc = times[-int(0.05*len(times))]\n",
    "\n",
    "train_data = cases_US[(cases_US.index.get_level_values(1).values >= last_5perc)]\n",
    "test_data = cases_US[(cases_US.index.get_level_values(1).values < last_5perc)]\n",
    "\n",
    "X_train, y_train = preprocess_data(train_data, 'Cases_2W', ['Avg_Temp'])\n",
    "X_test, y_test = preprocess_data(test_data, 'Cases_2W', ['Avg_Temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['minor/varies', 'R', '3', ..., '1.1106299212598423',\n",
       "         '0.07716535433070869', '33.55708661417321'],\n",
       "        ['minor/varies', 'R', '3', ..., '1.1106299212598423',\n",
       "         '0.07716535433070869', '33.55708661417321'],\n",
       "        ['minor/varies', 'R', '3', ..., '1.1106299212598423',\n",
       "         '0.07716535433070869', '33.55708661417321'],\n",
       "        ...,\n",
       "        ['moderate/varies', 'D', '1', ..., '1.52421052631579',\n",
       "         '0.05263157894736843', '3.7821052631578955'],\n",
       "        ['moderate/varies', 'D', '2', ..., '1.52421052631579',\n",
       "         '0.05263157894736843', '3.7821052631578955'],\n",
       "        ['moderate/varies', 'D', '2', ..., '1.52421052631579',\n",
       "         '0.05263157894736843', '3.7821052631578955']],\n",
       "\n",
       "       [['moderate', 'D', '3', ..., '2.4', '0.08', '6.9'],\n",
       "        ['minor', 'R', '2', ..., '0.9065217391304345',\n",
       "         '0.08043478260869566', '4.397826086956521'],\n",
       "        ['minor', 'R', '2', ..., '0.9065217391304345',\n",
       "         '0.08043478260869566', '4.397826086956521'],\n",
       "        ...,\n",
       "        ['minor/varies', 'R', '3', ..., '0.6852631578947368',\n",
       "         '0.048421052631578934', '3.258947368421051'],\n",
       "        ['minor/varies', 'R', '3', ..., '0.6852631578947368',\n",
       "         '0.048421052631578934', '3.258947368421051'],\n",
       "        ['minor/varies', 'R', '3', ..., '0.6852631578947368',\n",
       "         '0.048421052631578934', '3.258947368421051']],\n",
       "\n",
       "       [['moderate', 'D', '2', ..., '1.071875', '0.12812500000000004',\n",
       "         '46.02499999999999'],\n",
       "        ['moderate', 'D', '2', ..., '1.071875', '0.12812500000000004',\n",
       "         '46.02499999999999'],\n",
       "        ['moderate', 'D', '2', ..., '1.071875', '0.12812500000000004',\n",
       "         '46.02499999999999'],\n",
       "        ...,\n",
       "        ['minor', 'R', '3', ..., '0.49807692307692303',\n",
       "         '0.040384615384615394', '2.4788461538461544'],\n",
       "        ['minor', 'R', '3', ..., '0.49807692307692303',\n",
       "         '0.040384615384615394', '2.4788461538461544'],\n",
       "        ['minor', 'R', '3', ..., '0.49807692307692303',\n",
       "         '0.040384615384615394', '2.4788461538461544']],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [['moderate/varies', 'D', '1', ..., '1.1862745098039216',\n",
       "         '0.024509803921568638', '4.714705882352942'],\n",
       "        ['moderate/varies', 'D', '1', ..., '1.1862745098039216',\n",
       "         '0.024509803921568638', '4.714705882352942'],\n",
       "        ['moderate/varies', 'D', '1', ..., '1.1862745098039216',\n",
       "         '0.024509803921568638', '4.714705882352942'],\n",
       "        ...,\n",
       "        ['minor', 'R', '3', ..., '1.0393939393939395',\n",
       "         '0.06969696969696965', '4.327272727272727'],\n",
       "        ['minor', 'R', '3', ..., '1.0393939393939395',\n",
       "         '0.06969696969696965', '4.327272727272727'],\n",
       "        ['minor', 'R', '3', ..., '1.0393939393939395',\n",
       "         '0.06969696969696965', '4.327272727272727']],\n",
       "\n",
       "       [['moderate', 'D', '3', ..., '2.4', '0.08', '6.9'],\n",
       "        ['moderate', 'D', '3', ..., '2.4', '0.08', '6.9'],\n",
       "        ['moderate', 'D', '3', ..., '2.4', '0.08', '6.9'],\n",
       "        ...,\n",
       "        ['minor/varies', 'R', '3', ..., '0.6852631578947368',\n",
       "         '0.048421052631578934', '3.258947368421051'],\n",
       "        ['minor/varies', 'R', '3', ..., '0.6852631578947368',\n",
       "         '0.048421052631578934', '3.258947368421051'],\n",
       "        ['minor/varies', 'R', '3', ..., '0.6852631578947368',\n",
       "         '0.048421052631578934', '3.258947368421051']],\n",
       "\n",
       "       [['minor/varies', 'R', '3', ..., '1.1106299212598423',\n",
       "         '0.07716535433070869', '33.55708661417321'],\n",
       "        ['minor', 'R', '3', ..., '0.9931034482758622',\n",
       "         '0.3482758620689656', '8.786206896551725'],\n",
       "        ['minor', 'R', '3', ..., '0.9931034482758622',\n",
       "         '0.3482758620689656', '8.786206896551725'],\n",
       "        ...,\n",
       "        ['moderate/varies', 'D', '3', ..., '1.52421052631579',\n",
       "         '0.05263157894736843', '3.7821052631578955'],\n",
       "        ['moderate/varies', 'D', '3', ..., '1.52421052631579',\n",
       "         '0.05263157894736843', '3.7821052631578955'],\n",
       "        ['moderate/varies', 'D', '3', ..., '1.52421052631579',\n",
       "         '0.05263157894736843', '3.7821052631578955']]], dtype='<U20')"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 64)                158272    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 162,497\n",
      "Trainable params: 162,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, CuDNNLSTM, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "Epochs = 10\n",
    "Batch_Size = 64\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Dense(64, activation=tf.nn.relu, input_shape=[len(X_train)]),\n",
    "    layers.Dense(64, activation=tf.nn.relu),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "model.compile(loss='mse',\n",
    "             optimizer=optimizer,\n",
    "             metrics=['mae', 'mse'])\n",
    "\n",
    "# model.predict(X_test)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4775, 160, 11)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "cudagpu",
   "language": "python",
   "name": "cudagpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
